name: "Run gcs-to-bq-service"
description: "Triggers Cloud Run service to process source data (url, data/, or bucket) and write as tables to BigQuery."

inputs:
  workflow_id:
    description: "Workflow ID"
    required: true
  dataset_name:
    description: "Dataset Name"
    required: true
  demographic:
    description: "Demographic (optional)"
    required: false
    default: ""
  geographic:
    description: "Geographic (optional)"
    required: false
    default: ""

runs:
  using: "composite"
  steps:
    - run: |
        curl -X POST \
          -H "Content-Type: application/json" \
          -d "{\"message\":{\"is_airflow_run\":true,\"id\":\"${{ inputs.workflow_id }}\",\"gcs_bucket\":\"het-data-tables\",\"dataset\":\"${{ inputs.dataset_name }}\",\"demographic\":\"${{ inputs.demographic }}\"}}" \
          ${{ env.BQ_SERVICE_URL }}
      shell: bash
      env:
        BQ_SERVICE_URL: ${{ secrets.GCS_TO_BQ_SERVICE_URL }}

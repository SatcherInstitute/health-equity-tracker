name: "Run gcs-to-bq-service"
description: "Triggers Cloud Run service to process source data (url, data/, or bucket) and write as tables to BigQuery."

inputs:
  service_url:
    description: "GCS to BQ service URL"
    required: true
  workflow_id:
    description: "Workflow ID"
    required: true
  dataset_name:
    description: "Dataset Name"
    required: true
  demographic:
    description: "Demographic (optional)"
    required: false
    default: ""
  geographic:
    description: "Geographic (optional)"
    required: false
    default: ""
  year:
    description: "Year (optional)"
    required: false
    default: ""
  category:
    description: "Category (optional)"
    required: false
    default: ""
  filename:
    description: "Filename(s) (optional comma separated list of source file names in data/). NOTE: Only used by DECIA 2010 and should be hard coded into that data source module."
    required: false
    default: ""

runs:
  using: "composite"
  steps:
    - run: |
        curl -X POST \
          -H "Content-Type: application/json" \
          -d "{\"message\":{\"is_airflow_run\":true,\"id\":\"${{ inputs.workflow_id }}\",\"gcs_bucket\":\"het-data-tables\",\"dataset\":\"${{ inputs.dataset_name }}\",\"demographic\":\"${{ inputs.demographic }}\",\"filename\":\"${{ inputs.filename }}\",\"geographic\":\"${{ inputs.geographic }}\",\"year\":\"${{ inputs.year }}\",\"category\":\"${{ inputs.category }}\"}}" \
          ${{ inputs.service_url }}
      shell: bash

name: Deploy to Test

on:
  push:
      branches: [master]
  workflow_dispatch:

jobs:
  deploy:
    if: github.repository == 'SatcherInstitute/health-equity-tracker'    
    name: Build Images and Deploy to Test Environment
    runs-on: ubuntu-latest

    steps: 
      - name: Check Out Code
        uses: actions/checkout@v2
      - name: Set Up gcloud
        uses: google-github-actions/setup-gcloud@master
        with:
          export_default_credentials: true
          service_account_key: ${{ secrets.TEST_DEPLOYER_SA_KEY }}
          project_id: ${{ secrets.TEST_PROJECT_ID }}
      - name: Set Up Docker to Use gcloud Credentials
        run: gcloud auth configure-docker -q
      - name: Build and Push Data Serving Image
        uses: ./.github/actions/buildAndPush
        with:
          dockerfile: 'data_server/Dockerfile'
          image-path: 'gcr.io/${{ secrets.TEST_PROJECT_ID }}/data-server'
      - name: Build and Push Data Ingestion Image
        uses: ./.github/actions/buildAndPush
        with:
          dockerfile: 'run_ingestion/Dockerfile'
          image-path: 'gcr.io/${{ secrets.TEST_PROJECT_ID }}/data-ingestion'  
      - name: Build and Push GCS to BQ Image
        uses: ./.github/actions/buildAndPush
        with:
          dockerfile: 'run_gcs_to_bq/Dockerfile'
          image-path: 'gcr.io/${{ secrets.TEST_PROJECT_ID }}/gcs-to-bq'
      - name: Build and Push Exporter Image
        uses: ./.github/actions/buildAndPush
        with:
          dockerfile: 'exporter/Dockerfile'
          image-path: 'gcr.io/${{ secrets.TEST_PROJECT_ID }}/exporter'
      - name: Build and Push Aggregator Image
        uses: ./.github/actions/buildAndPush
        with:
          dockerfile: 'aggregator/Dockerfile'
          image-path: 'gcr.io/${{ secrets.TEST_PROJECT_ID }}/aggregator'
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        # Disable wrapper to enable access to terraform output.
        with:
          terraform_wrapper: false
      - name: Save credentials
        working-directory: ./config
        run: |
          cat > creds.json << EOF 
          ${{ secrets.TEST_DEPLOYER_SA_KEY }}
          EOF
      - name: Terraform Init
        working-directory: ./config
        run: | 
          terraform init -backend-config="bucket=${{ secrets.TEST_TF_STATE_BUCKET }}" \
          -backend-config="credentials=creds.json"
      - name: Terraform Apply
        id: terraform
        if: github.ref == 'refs/heads/master' && github.event_name == 'push'
        working-directory: ./config
        run: |
          terraform apply -auto-approve -var-file=test/test.tfvars \
          -var 'gcp_credentials=${{ secrets.TEST_DEPLOYER_SA_KEY }}' \
          -var 'project_id=${{ secrets.TEST_PROJECT_ID }}'
          data_server_url=$(terraform output data_server_url)
          echo "::set-output name=data_server_url::$data_server_url"
          ingestion_url=$(terraform output ingestion_url)
          echo "::set-output name=ingestion_url::$ingestion_url"
          gcs_to_bq_url=$(terraform output gcs_to_bq_url)
          echo "::set-output name=gcs_to_bq_url::$gcs_to_bq_url"
          exporter_url=$(terraform output exporter_url)
          echo "::set-output name=exporter_url::$exporter_url"
          aggregator_url=$(terraform output aggregator_url)
          echo "::set-output name=aggregator_url::$aggregator_url"
      - name: Airflow Environment Variables
        id: airflow-environment-variables
        if: github.ref == 'refs/heads/master' && github.event_name == 'push'
        continue-on-error: true
        run: |
          gcloud composer environments update data-ingestion-environment \
          --update-env-variables=AIRFLOW_VAR_INGEST_TO_GCS_SERVICE_ENDPOINT=${{ steps.terraform.outputs.ingestion_url }} \
          --update-env-variables=AIRFLOW_VAR_GCS_TO_BQ_SERVICE_ENDPOINT=${{ steps.terraform.outputs.gcs_to_bq_url }} \
          --update-env-variables=AIRFLOW_VAR_EXPORTER_SERVICE_ENDPOINT=${{ steps.terraform.outputs.exporter_url }} \
          --update-env-variables=AIRFLOW_VAR_GCS_LANDING_BUCKET=msm-test-landing-bucket \
          --update-env-variables=AIRFLOW_VAR_GCS_MANUAL_UPLOADS_BUCKET=msm-test-manual-data-bucket \
          --location=us-central1
      - name: Upload Airflow utility file
        if: github.ref == 'refs/heads/master' && github.event_name == 'push'
        working-directory: ./airflow/dags
        run: |
          gcloud composer environments storage dags import \
          --environment data-ingestion-environment \
          --source util.py \
          --location=us-central1
      - name: Upload Airflow DAG
        if: github.ref == 'refs/heads/master' && github.event_name == 'push'
        working-directory: ./airflow/dags
        run: |
          gcloud composer environments storage dags import \
          --environment data-ingestion-environment \
          --source ingestion.py \
          --location=us-central1
      - name: Upload Airflow manual DAG
        if: github.ref == 'refs/heads/master' && github.event_name == 'push'
        working-directory: ./airflow/dags
        run: |
          gcloud composer environments storage dags import \
          --environment data-ingestion-environment \
          --source manual_ingestion.py \
          --location=us-central1
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Run E2E Tests
        run: |
          pip install -r e2e_tests/requirements.txt
          python e2e_tests/data_serving.py || code=$?; if [[ $code -ne 0 ]]; then exit $code; fi
        env:
          SERVICE_URL: ${{ steps.terraform.outputs.data_server_url }}
